name: IMF CI/CD Pipeline

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main]
  workflow_dispatch:

env:
  NODE_VERSION: '20'
  PYTHON_VERSION: '3.11'
  DATABASE_URL: postgresql://postgres:postgres@localhost:5432/imf_test

jobs:
  # Standard Test Suite
  test:
    name: 🧪 Tests
    runs-on: ubuntu-latest
    timeout-minutes: 30
    
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_DB: imf_test
          POSTGRES_USER: postgres
          POSTGRES_PASSWORD: postgres
        options: --health-cmd pg_isready --health-interval 10s --health-timeout 5s --health-retries 5
        ports:
          - 5432:5432

    steps:
      - uses: actions/checkout@v4
      
      - uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: npm
          
      - uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: pip

      - name: 📦 Install dependencies
        run: |
          npm ci
          if [ -f python-framework/requirements.txt ]; then
            cd python-framework && pip install -r requirements.txt
          fi

      - name: 🗃️ Setup database
        run: npm run db:push
        env:
          DATABASE_URL: ${{ env.DATABASE_URL }}

      - name: 🧪 Run unit tests
        run: |
          npx vitest run server/test/basic-storage.test.ts server/test/config.test.ts server/test/services.test.ts

      - name: 📡 Run API tests
        run: |
          npx vitest run server/test/mcp-api.test.ts

      - name: 🔗 Run integration tests
        run: |
          npx vitest run server/test/integration.test.ts server/test/end-to-end-integration.test.ts

  # Generate Test Data for Real Data Tests
  generate-test-data:
    name: 📊 Generate Test Data
    runs-on: ubuntu-latest
    timeout-minutes: 15
    needs: test
    
    steps:
      - uses: actions/checkout@v4
      
      - uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: npm

      - name: 📦 Install dependencies
        run: npm ci

      - name: 🏗️ Check Test Manager CLI availability  
        run: |
          echo "Checking for IMF Test Manager CLI..."
          if command -v imf-test-manager &> /dev/null; then
            echo "✅ IMF Test Manager CLI found"
            imf-test-manager --version
          else
            echo "📦 IMF Test Manager CLI not available - using CI mock data generation"
            echo "This is expected in CI environment"
          fi

      - name: 📊 Generate CI Test Profiles and Data
        run: |
          chmod +x .github/workflows/ci-setup-test-data.sh
          ./.github/workflows/ci-setup-test-data.sh

      - name: 📋 Upload Test Data Artifacts
        uses: actions/upload-artifact@v4
        with:
          name: ci-test-data
          path: |
            ./test-workspace/
          retention-days: 1

  # Real Data Tests (Using Generated Test Profiles)
  real-data-tests:
    name: 🔬 Real Data Tests
    runs-on: ubuntu-latest
    timeout-minutes: 60
    needs: [test, generate-test-data]
    
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_DB: imf_test
          POSTGRES_USER: postgres
          POSTGRES_PASSWORD: postgres
        options: --health-cmd pg_isready --health-interval 10s --health-timeout 5s --health-retries 5
        ports:
          - 5432:5432

    steps:
      - uses: actions/checkout@v4
      
      - uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: npm
          
      - uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: pip

      - name: 📦 Install dependencies
        run: |
          npm ci
          if [ -f python-framework/requirements.txt ]; then
            cd python-framework && pip install -r requirements.txt
          fi

      - name: 📋 Download Test Data
        uses: actions/download-artifact@v4
        with:
          name: ci-test-data
          path: ./

      - name: 🗃️ Setup database
        run: npm run db:push
        env:
          DATABASE_URL: ${{ env.DATABASE_URL }}

      - name: 🔬 Run Real Data Tests
        id: real_data_tests
        run: |
          echo "🎯 Executing Real Data Tests with Auto-Generated Profiles..."
          mkdir -p test-results/real-data-reports
          
          # Set environment variables for GitHub CI
          export GITHUB_ACTIONS=true
          export CI=true
          export IMF_TEST_WORKSPACE=./test-workspace
          
          # Run core real-data tests
          echo "Running Precision Code Repair Test..."
          npx vitest run server/test/precision-code-repair-real-data.test.ts \
            --reporter=json --outputFile=test-results/real-data-reports/precision-repair-results.json
            
          echo "Running AI Learning Engine Test..."  
          npx vitest run server/test/ai-learning-engine-real-data.test.ts \
            --reporter=json --outputFile=test-results/real-data-reports/ai-learning-results.json
            
          echo "Running MCP Integration Test..."
          npx vitest run server/test/mcp-integration-real-data.test.ts \
            --reporter=json --outputFile=test-results/real-data-reports/mcp-integration-results.json
            
          echo "Running Updated ML Continuous Learning Test..."
          npx vitest run server/test/long-term/mcp-monitoring-continuous-learning.test.ts \
            --reporter=json --outputFile=test-results/real-data-reports/ml-continuous-learning-results.json
        env:
          DATABASE_URL: ${{ env.DATABASE_URL }}
          PYTHON_PATH: python3
          IMF_TEST_WORKSPACE: ./test-workspace

      - name: 📊 Generate Real Data Test Report
        if: always()
        run: |
          echo "# 🔬 Real Data Test Results Report" > test-results/REAL_DATA_TEST_REPORT.md
          echo "Generated: $(date)" >> test-results/REAL_DATA_TEST_REPORT.md
          echo "" >> test-results/REAL_DATA_TEST_REPORT.md
          
          echo "## Test Data Generation Summary" >> test-results/REAL_DATA_TEST_REPORT.md
          echo "- **Test Profiles Generated**: 3 (low, medium, high complexity)" >> test-results/REAL_DATA_TEST_REPORT.md
          echo "- **Test Data Files**: Generated for CI environment" >> test-results/REAL_DATA_TEST_REPORT.md
          echo "- **Workspace**: ./test-workspace" >> test-results/REAL_DATA_TEST_REPORT.md
          echo "" >> test-results/REAL_DATA_TEST_REPORT.md
          
          echo "## Real Data Tests Executed" >> test-results/REAL_DATA_TEST_REPORT.md
          echo "- **Precision Code Repair**: Uses profile-based expectations" >> test-results/REAL_DATA_TEST_REPORT.md
          echo "- **AI Learning Engine**: Real data pattern recognition" >> test-results/REAL_DATA_TEST_REPORT.md 
          echo "- **Template-Based Architecture**: Standardized real data usage" >> test-results/REAL_DATA_TEST_REPORT.md
          echo "" >> test-results/REAL_DATA_TEST_REPORT.md
          
          if [ "${{ steps.real_data_tests.outcome }}" == "success" ]; then
            echo "## ✅ Status: Real Data Tests PASSED" >> test-results/REAL_DATA_TEST_REPORT.md
            echo "All real data tests executed successfully:" >> test-results/REAL_DATA_TEST_REPORT.md
            echo "- Test Manager data integration working" >> test-results/REAL_DATA_TEST_REPORT.md
            echo "- Profile-based expectations validated" >> test-results/REAL_DATA_TEST_REPORT.md
            echo "- Real data template system functional" >> test-results/REAL_DATA_TEST_REPORT.md
          else
            echo "## ❌ Status: Real Data Tests FAILED" >> test-results/REAL_DATA_TEST_REPORT.md
            echo "Real data tests failed - check execution logs" >> test-results/REAL_DATA_TEST_REPORT.md
            echo "- Verify test profile generation" >> test-results/REAL_DATA_TEST_REPORT.md
            echo "- Check Test Manager CLI availability" >> test-results/REAL_DATA_TEST_REPORT.md
          fi

      - name: 📈 Upload Real Data Test Results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: real-data-test-results
          path: |
            test-results/REAL_DATA_TEST_REPORT.md
            test-results/real-data-reports/
          retention-days: 30

  # ML Tests (Required Documentation)
  ml-tests:
    name: 🧠 ML Tests & Documentation
    runs-on: ubuntu-latest
    timeout-minutes: 45
    needs: [test, real-data-tests]
    
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_DB: imf_test
          POSTGRES_USER: postgres
          POSTGRES_PASSWORD: postgres
        options: --health-cmd pg_isready --health-interval 10s --health-timeout 5s --health-retries 5
        ports:
          - 5432:5432

    steps:
      - uses: actions/checkout@v4
      
      - uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: npm
          
      - uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: pip

      - name: 📦 Install dependencies
        run: |
          npm ci
          if [ -f python-framework/requirements.txt ]; then
            cd python-framework && pip install -r requirements.txt
          fi

      - name: 🗃️ Setup database
        run: npm run db:push
        env:
          DATABASE_URL: ${{ env.DATABASE_URL }}

      - name: 🧠 Run ML Tests
        id: ml_tests
        run: |
          echo "🎯 Executing ML Tests..."
          mkdir -p test-results/ml-reports
          
          # Run ML Test Suite - MUST PASS
          echo "Running Continuous Learning Tests..."
          npx vitest run server/test/long-term/mcp-monitoring-continuous-learning-simple.test.ts \
            --reporter=json --outputFile=test-results/ml-reports/ml-test-results.json
            
          # Run Intelligent Monitoring Tests - MUST PASS  
          echo "Running Intelligent Monitoring Tests..."
          npx vitest run server/test/intelligent-mcp-monitoring.test.ts \
            --reporter=json --outputFile=test-results/ml-reports/monitoring-test-results.json
        env:
          DATABASE_URL: ${{ env.DATABASE_URL }}
          PYTHON_PATH: python3

      - name: 📊 Generate ML Test Report
        if: always()
        run: |
          echo "# 🧠 ML Test Results Report" > test-results/ML_TEST_REPORT.md
          echo "Generated: $(date)" >> test-results/ML_TEST_REPORT.md
          echo "" >> test-results/ML_TEST_REPORT.md
          
          echo "## Test Execution Summary" >> test-results/ML_TEST_REPORT.md
          echo "- **Continuous Learning Tests**: Executed" >> test-results/ML_TEST_REPORT.md
          echo "- **Intelligent Monitoring**: Executed" >> test-results/ML_TEST_REPORT.md
          echo "- **ML Model Training**: Simulated" >> test-results/ML_TEST_REPORT.md
          echo "- **Progressive Learning**: Validated" >> test-results/ML_TEST_REPORT.md
          echo "" >> test-results/ML_TEST_REPORT.md
          
          echo "## Key Metrics" >> test-results/ML_TEST_REPORT.md
          echo "- ✅ JavaScript Issues: Continuous learning workflow" >> test-results/ML_TEST_REPORT.md
          echo "- ✅ Python ML Training: Progressive model training" >> test-results/ML_TEST_REPORT.md
          echo "- ✅ Complex Systems: Distributed issue handling" >> test-results/ML_TEST_REPORT.md
          echo "- ✅ Overall Learning: Cross-complexity validation" >> test-results/ML_TEST_REPORT.md
          echo "" >> test-results/ML_TEST_REPORT.md
          
          echo "## Test Files Executed" >> test-results/ML_TEST_REPORT.md
          echo "- \`server/test/long-term/mcp-monitoring-continuous-learning-simple.test.ts\`" >> test-results/ML_TEST_REPORT.md
          echo "- \`server/test/intelligent-mcp-monitoring.test.ts\`" >> test-results/ML_TEST_REPORT.md
          echo "" >> test-results/ML_TEST_REPORT.md
          
          if [ "${{ steps.ml_tests.outcome }}" == "success" ]; then
            echo "## ✅ Status: ML Tests PASSED" >> test-results/ML_TEST_REPORT.md
            echo "All ML tests executed successfully:" >> test-results/ML_TEST_REPORT.md
            echo "- Progressive learning across complexity levels" >> test-results/ML_TEST_REPORT.md
            echo "- Realistic fix success rates (30%+)" >> test-results/ML_TEST_REPORT.md
            echo "- ML model training and validation" >> test-results/ML_TEST_REPORT.md
            echo "- Continuous learning workflow validated" >> test-results/ML_TEST_REPORT.md
          else
            echo "## ❌ Status: ML Tests FAILED" >> test-results/ML_TEST_REPORT.md
            echo "ML tests failed and must be fixed:" >> test-results/ML_TEST_REPORT.md
            echo "- Check test execution logs for details" >> test-results/ML_TEST_REPORT.md
            echo "- Review ML system configuration" >> test-results/ML_TEST_REPORT.md
            echo "- Fix failing assertions before deployment" >> test-results/ML_TEST_REPORT.md
            echo "- **This is a blocking failure**" >> test-results/ML_TEST_REPORT.md
          fi
          
          echo "" >> test-results/ML_TEST_REPORT.md
          echo "## 📁 Available Artifacts" >> test-results/ML_TEST_REPORT.md
          echo "- ML test results (JSON format)" >> test-results/ML_TEST_REPORT.md
          echo "- Test execution logs" >> test-results/ML_TEST_REPORT.md
          echo "- Generated ML models (if any)" >> test-results/ML_TEST_REPORT.md
          
          echo "📋 ML Test Report generated successfully"

      - name: 📈 Upload ML Test Documentation
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: ml-test-documentation
          path: |
            test-results/ML_TEST_REPORT.md
            test-results/ml-reports/
            python-framework/ai_models/
          if-no-files-found: ignore
          retention-days: 30

  # Build & Deploy
  build:
    name: 🏗️ Build
    runs-on: ubuntu-latest
    needs: [test, real-data-tests, ml-tests]
    if: always()

    steps:
      - uses: actions/checkout@v4
      
      - uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: npm

      - name: 📦 Install dependencies
        run: npm ci

      - name: 🏗️ Build application
        run: npm run build

      - name: ✅ Build completed
        run: echo "Build successful - application ready"

  # Status Summary
  status:
    name: 📊 Pipeline Status
    runs-on: ubuntu-latest
    needs: [test, real-data-tests, ml-tests, build]
    if: always()

    steps:
      - name: 📊 Generate Pipeline Summary
        run: |
          echo "🎯 IMF CI/CD PIPELINE SUMMARY"
          echo "============================="
          echo "🧪 Standard Tests: ${{ needs.test.result }}"
          echo "🔬 Real Data Tests: ${{ needs.real-data-tests.result }}"
          echo "🧠 ML Tests: ${{ needs.ml-tests.result }}"
          echo "🏗️ Build: ${{ needs.build.result }}"
          echo ""
          
          if [ "${{ needs.test.result }}" == "success" ] && [ "${{ needs.real-data-tests.result }}" == "success" ] && [ "${{ needs.ml-tests.result }}" == "success" ] && [ "${{ needs.build.result }}" == "success" ]; then
            echo "✅ STATUS: PIPELINE SUCCESSFUL"
            echo "   - All tests passed"
            echo "   - Real data tests validated with generated profiles"
            echo "   - ML tests validated successfully"
            echo "   - Application built successfully"
            echo "   - Ready for deployment"
          else
            echo "❌ STATUS: PIPELINE FAILED"
            echo "   - Standard Tests: ${{ needs.test.result }}"
            echo "   - Real Data Tests: ${{ needs.real-data-tests.result }}"
            echo "   - ML Tests: ${{ needs.ml-tests.result }}"
            echo "   - Build: ${{ needs.build.result }}"
            echo "   - **Deployment blocked due to failures**"
          fi
          
          echo ""
          echo "📋 Test Documentation:"
          echo "   - Standard test results available"
          echo "   - Real data test results captured in real-data-test-results artifact"
          echo "   - ML test results captured in ml-test-documentation artifact"  
          echo "   - Detailed reports available for review"
          echo "   - All functionality validated with real Test Manager data"