name: IMF CI/CD Pipeline

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main]
  workflow_dispatch:

env:
  NODE_VERSION: '20'
  PYTHON_VERSION: '3.11'
  DATABASE_URL: postgresql://postgres:postgres@localhost:5432/imf_test

jobs:
  # Standard Test Suite
  test:
    name: 🧪 Tests
    runs-on: ubuntu-latest
    timeout-minutes: 30
    
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_DB: imf_test
          POSTGRES_USER: postgres
          POSTGRES_PASSWORD: postgres
        options: --health-cmd pg_isready --health-interval 10s --health-timeout 5s --health-retries 5
        ports:
          - 5432:5432

    steps:
      - uses: actions/checkout@v4
      
      - uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: npm
          
      - uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: pip

      - name: 📦 Install dependencies
        run: |
          npm ci
          if [ -f python-framework/requirements.txt ]; then
            cd python-framework && pip install -r requirements.txt
          fi

      - name: 🗃️ Setup database
        run: npm run db:push
        env:
          DATABASE_URL: ${{ env.DATABASE_URL }}

      - name: 🧪 Run unit tests
        run: |
          npx vitest run server/test/basic-storage.test.ts server/test/config.test.ts server/test/services.test.ts

      - name: 📡 Run API tests
        run: |
          npx vitest run server/test/mcp-api.test.ts

      - name: 🔗 Run integration tests
        run: |
          npx vitest run server/test/integration.test.ts server/test/end-to-end-integration.test.ts

  # ML Tests (Required Documentation)
  ml-tests:
    name: 🧠 ML Tests & Documentation
    runs-on: ubuntu-latest
    timeout-minutes: 45
    needs: test
    
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_DB: imf_test
          POSTGRES_USER: postgres
          POSTGRES_PASSWORD: postgres
        options: --health-cmd pg_isready --health-interval 10s --health-timeout 5s --health-retries 5
        ports:
          - 5432:5432

    steps:
      - uses: actions/checkout@v4
      
      - uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: npm
          
      - uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: pip

      - name: 📦 Install dependencies
        run: |
          npm ci
          if [ -f python-framework/requirements.txt ]; then
            cd python-framework && pip install -r requirements.txt
          fi

      - name: 🗃️ Setup database
        run: npm run db:push
        env:
          DATABASE_URL: ${{ env.DATABASE_URL }}

      - name: 🧠 Run ML Tests
        id: ml_tests
        run: |
          echo "🎯 Executing ML Tests..."
          mkdir -p test-results/ml-reports
          
          # Run ML Test Suite - MUST PASS
          echo "Running Continuous Learning Tests..."
          npx vitest run server/test/long-term/mcp-monitoring-continuous-learning-simple.test.ts \
            --reporter=json --outputFile=test-results/ml-reports/ml-test-results.json
            
          # Run Intelligent Monitoring Tests - MUST PASS  
          echo "Running Intelligent Monitoring Tests..."
          npx vitest run server/test/intelligent-mcp-monitoring.test.ts \
            --reporter=json --outputFile=test-results/ml-reports/monitoring-test-results.json
        env:
          DATABASE_URL: ${{ env.DATABASE_URL }}
          PYTHON_PATH: python3

      - name: 📊 Generate ML Test Report
        if: always()
        run: |
          echo "# 🧠 ML Test Results Report" > test-results/ML_TEST_REPORT.md
          echo "Generated: $(date)" >> test-results/ML_TEST_REPORT.md
          echo "" >> test-results/ML_TEST_REPORT.md
          
          echo "## Test Execution Summary" >> test-results/ML_TEST_REPORT.md
          echo "- **Continuous Learning Tests**: Executed" >> test-results/ML_TEST_REPORT.md
          echo "- **Intelligent Monitoring**: Executed" >> test-results/ML_TEST_REPORT.md
          echo "- **ML Model Training**: Simulated" >> test-results/ML_TEST_REPORT.md
          echo "- **Progressive Learning**: Validated" >> test-results/ML_TEST_REPORT.md
          echo "" >> test-results/ML_TEST_REPORT.md
          
          echo "## Key Metrics" >> test-results/ML_TEST_REPORT.md
          echo "- ✅ JavaScript Issues: Continuous learning workflow" >> test-results/ML_TEST_REPORT.md
          echo "- ✅ Python ML Training: Progressive model training" >> test-results/ML_TEST_REPORT.md
          echo "- ✅ Complex Systems: Distributed issue handling" >> test-results/ML_TEST_REPORT.md
          echo "- ✅ Overall Learning: Cross-complexity validation" >> test-results/ML_TEST_REPORT.md
          echo "" >> test-results/ML_TEST_REPORT.md
          
          echo "## Test Files Executed" >> test-results/ML_TEST_REPORT.md
          echo "- \`server/test/long-term/mcp-monitoring-continuous-learning-simple.test.ts\`" >> test-results/ML_TEST_REPORT.md
          echo "- \`server/test/intelligent-mcp-monitoring.test.ts\`" >> test-results/ML_TEST_REPORT.md
          echo "" >> test-results/ML_TEST_REPORT.md
          
          if [ "${{ steps.ml_tests.outcome }}" == "success" ]; then
            echo "## ✅ Status: ML Tests PASSED" >> test-results/ML_TEST_REPORT.md
            echo "All ML tests executed successfully:" >> test-results/ML_TEST_REPORT.md
            echo "- Progressive learning across complexity levels" >> test-results/ML_TEST_REPORT.md
            echo "- Realistic fix success rates (30%+)" >> test-results/ML_TEST_REPORT.md
            echo "- ML model training and validation" >> test-results/ML_TEST_REPORT.md
            echo "- Continuous learning workflow validated" >> test-results/ML_TEST_REPORT.md
          else
            echo "## ❌ Status: ML Tests FAILED" >> test-results/ML_TEST_REPORT.md
            echo "ML tests failed and must be fixed:" >> test-results/ML_TEST_REPORT.md
            echo "- Check test execution logs for details" >> test-results/ML_TEST_REPORT.md
            echo "- Review ML system configuration" >> test-results/ML_TEST_REPORT.md
            echo "- Fix failing assertions before deployment" >> test-results/ML_TEST_REPORT.md
            echo "- **This is a blocking failure**" >> test-results/ML_TEST_REPORT.md
          fi
          
          echo "" >> test-results/ML_TEST_REPORT.md
          echo "## 📁 Available Artifacts" >> test-results/ML_TEST_REPORT.md
          echo "- ML test results (JSON format)" >> test-results/ML_TEST_REPORT.md
          echo "- Test execution logs" >> test-results/ML_TEST_REPORT.md
          echo "- Generated ML models (if any)" >> test-results/ML_TEST_REPORT.md
          
          echo "📋 ML Test Report generated successfully"

      - name: 📈 Upload ML Test Documentation
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: ml-test-documentation
          path: |
            test-results/ML_TEST_REPORT.md
            test-results/ml-reports/
            python-framework/ai_models/
          if-no-files-found: ignore
          retention-days: 30

  # Build & Deploy
  build:
    name: 🏗️ Build
    runs-on: ubuntu-latest
    needs: [test, ml-tests]
    if: always()

    steps:
      - uses: actions/checkout@v4
      
      - uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: npm

      - name: 📦 Install dependencies
        run: npm ci

      - name: 🏗️ Build application
        run: npm run build

      - name: ✅ Build completed
        run: echo "Build successful - application ready"

  # Status Summary
  status:
    name: 📊 Pipeline Status
    runs-on: ubuntu-latest
    needs: [test, ml-tests, build]
    if: always()

    steps:
      - name: 📊 Generate Pipeline Summary
        run: |
          echo "🎯 IMF CI/CD PIPELINE SUMMARY"
          echo "============================="
          echo "🧪 Standard Tests: ${{ needs.test.result }}"
          echo "🧠 ML Tests: ${{ needs.ml-tests.result }}"
          echo "🏗️ Build: ${{ needs.build.result }}"
          echo ""
          
          if [ "${{ needs.test.result }}" == "success" ] && [ "${{ needs.ml-tests.result }}" == "success" ] && [ "${{ needs.build.result }}" == "success" ]; then
            echo "✅ STATUS: PIPELINE SUCCESSFUL"
            echo "   - All tests passed"
            echo "   - ML tests validated successfully"
            echo "   - Application built successfully"
            echo "   - Ready for deployment"
          else
            echo "❌ STATUS: PIPELINE FAILED"
            echo "   - Standard Tests: ${{ needs.test.result }}"
            echo "   - ML Tests: ${{ needs.ml-tests.result }}"
            echo "   - Build: ${{ needs.build.result }}"
            echo "   - **Deployment blocked due to failures**"
          fi
          
          echo ""
          echo "📋 ML Test Documentation:"
          echo "   - Results captured in ml-test-documentation artifact"  
          echo "   - Detailed report available for review"
          echo "   - All ML functionality validated"