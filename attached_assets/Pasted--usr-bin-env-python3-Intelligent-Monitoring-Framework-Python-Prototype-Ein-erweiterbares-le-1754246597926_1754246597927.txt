#!/usr/bin/env python3
"""
Intelligent Monitoring Framework - Python Prototype
Ein erweiterbares, lernfähiges Framework für Server-Monitoring mit Log-Analyse
"""

import asyncio
import logging
import json
import re
import time
import os
import sys
from abc import ABC, abstractmethod
from dataclasses import dataclass, field, asdict
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional, Pattern
from collections import defaultdict, deque, Counter
from pathlib import Path
import yaml
import psutil
import hashlib
from enum import Enum

# Setup logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# ============================================================================
# CORE FRAMEWORK CLASSES
# ============================================================================

class ProblemSeverity(Enum):
    LOW = 1
    MEDIUM = 2
    HIGH = 3
    CRITICAL = 4

@dataclass
class FrameworkConfig:
    """Framework Konfiguration"""
    server_type: str = "generic"
    monitoring_interval: int = 30
    learning_enabled: bool = True
    auto_remediation: bool = True
    log_level: str = "INFO"
    data_dir: str = "./data"
    plugin_dirs: List[str] = field(default_factory=lambda: ["plugins"])

@dataclass
class LogEntry:
    """Log-Eintrag Datenstruktur"""
    timestamp: datetime
    level: str
    message: str
    source: str
    raw_line: str = ""
    metadata: Dict[str, Any] = field(default_factory=dict)

@dataclass
class Problem:
    """Erkanntes Problem"""
    type: str
    severity: ProblemSeverity
    description: str
    timestamp: datetime
    metadata: Dict[str, Any] = field(default_factory=dict)
    
    def to_dict(self) -> Dict[str, Any]:
        data = asdict(self)
        data['severity'] = self.severity.name
        data['timestamp'] = self.timestamp.isoformat()
        return data

# ============================================================================
# PLUGIN INTERFACES
# ============================================================================

class PluginInterface(ABC):
    """Basis-Interface für alle Plugins"""
    
    @property
    @abstractmethod
    def name(self) -> str:
        pass
    
    @property
    @abstractmethod
    def version(self) -> str:
        pass
    
    @abstractmethod
    async def initialize(self, config: Dict[str, Any]) -> bool:
        pass
    
    @abstractmethod
    async def cleanup(self) -> None:
        pass

class MetricsCollectorPlugin(PluginInterface):
    """Interface für Metriken-Sammler"""
    
    @abstractmethod
    async def collect_metrics(self) -> Dict[str, Any]:
        pass

class ProblemDetectorPlugin(PluginInterface):
    """Interface für Problem-Erkennung"""
    
    @abstractmethod
    async def detect_problems(self, metrics: Dict[str, Any], 
                            history: List[Dict[str, Any]]) -> List[Problem]:
        pass

class RemediationPlugin(PluginInterface):
    """Interface für automatische Problemlösung"""
    
    @abstractmethod
    async def can_handle_problem(self, problem: Problem) -> bool:
        pass
    
    @abstractmethod
    async def execute_remediation(self, problem: Problem, 
                                context: Dict[str, Any]) -> Dict[str, Any]:
        pass

# ============================================================================
# LOG MONITORING PLUGINS
# ============================================================================

class LogFileCollectorPlugin(MetricsCollectorPlugin):
    """Sammelt und analysiert Log-Files"""
    
    def __init__(self):
        self.log_files = []
        self.log_buffer = deque(maxlen=1000)
        self.file_positions = {}
        
    @property
    def name(self) -> str:
        return "log_file_collector"
    
    @property
    def version(self) -> str:
        return "1.0.0"
    
    async def initialize(self, config: Dict[str, Any]) -> bool:
        self.log_files = config.get('log_files', [])
        logger.info(f"Initialized log collector with {len(self.log_files)} files")
        
        # Initialize file positions
        for log_file in self.log_files:
            path = Path(log_file['path'])
            if path.exists():
                self.file_positions[log_file['path']] = path.stat().st_size
            else:
                logger.warning(f"Log file not found: {log_file['path']}")
        
        return True
    
    async def cleanup(self) -> None:
        pass
    
    async def collect_metrics(self) -> Dict[str, Any]:
        """Sammelt Log-basierte Metriken"""
        metrics = {
            'log_collector_active': True,
            'log_files_monitored': len(self.log_files)
        }
        
        total_new_entries = 0
        error_count = 0
        warning_count = 0
        
        for log_file_config in self.log_files:
            try:
                new_entries = await self._process_log_file(log_file_config)
                total_new_entries += len(new_entries)
                
                # Count by level
                for entry in new_entries:
                    if entry.level == 'ERROR':
                        error_count += 1
                    elif entry.level == 'WARNING':
                        warning_count += 1
                    
                    self.log_buffer.append(entry)
                
            except Exception as e:
                logger.error(f"Error processing {log_file_config['path']}: {e}")
        
        metrics.update({
            'log_new_entries': total_new_entries,
            'log_error_count': error_count,
            'log_warning_count': warning_count,
            'log_buffer_size': len(self.log_buffer)
        })
        
        return metrics
    
    async def _process_log_file(self, log_config: Dict[str, Any]) -> List[LogEntry]:
        """Verarbeitet einzelne Log-Datei"""
        log_path = log_config['path']
        log_type = log_config.get('type', 'generic')
        
        if not Path(log_path).exists():
            return []
        
        new_lines = await self._read_new_lines(log_path)
        entries = []
        
        for line in new_lines:
            entry = await self._parse_log_line(line, log_type)
            if entry:
                entries.append(entry)
        
        return entries
    
    async def _read_new_lines(self, log_path: str) -> List[str]:
        """Liest nur neue Zeilen seit letztem Check"""
        path = Path(log_path)
        current_size = path.stat().st_size
        last_position = self.file_positions.get(log_path, 0)
        
        if current_size <= last_position:
            # File rotated oder kleiner
            last_position = 0
        
        new_lines = []
        try:
            with open(log_path, 'r', encoding='utf-8', errors='ignore') as f:
                f.seek(last_position)
                content = f.read()
                if content.strip():
                    new_lines = content.strip().split('\n')
            
            self.file_positions[log_path] = current_size
            
        except Exception as e:
            logger.error(f"Error reading {log_path}: {e}")
        
        return new_lines
    
    async def _parse_log_line(self, line: str, log_type: str) -> Optional[LogEntry]:
        """Parst Log-Zeile basierend auf Typ"""
        
        if not line.strip():
            return None
        
        # JSON Format
        if line.strip().startswith('{'):
            try:
                data = json.loads(line)
                timestamp = self._parse_timestamp(
                    data.get('timestamp', data.get('time', ''))
                )
                return LogEntry(
                    timestamp=timestamp,
                    level=data.get('level', 'INFO').upper(),
                    message=data.get('message', data.get('msg', '')),
                    source=log_type,
                    raw_line=line,
                    metadata=data
                )
            except json.JSONDecodeError:
                pass
        
        # Standard Log Format: "YYYY-MM-DD HH:MM:SS LEVEL MESSAGE"
        standard_pattern = re.compile(
            r'(?P<timestamp>\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}[^\s]*)\s+'
            r'(?P<level>DEBUG|INFO|WARN|WARNING|ERROR|FATAL)\s+'
            r'(?P<message>.*)'
        )
        
        match = standard_pattern.match(line)
        if match:
            timestamp = self._parse_timestamp(match.group('timestamp'))
            return LogEntry(
                timestamp=timestamp,
                level=match.group('level'),
                message=match.group('message'),
                source=log_type,
                raw_line=line
            )
        
        # Fallback: Generic parsing
        return LogEntry(
            timestamp=datetime.now(),
            level='INFO',
            message=line,
            source=log_type,
            raw_line=line
        )
    
    def _parse_timestamp(self, timestamp_str: str) -> datetime:
        """Parst Timestamp-String"""
        if not timestamp_str:
            return datetime.now()
        
        formats = [
            '%Y-%m-%d %H:%M:%S',
            '%Y-%m-%dT%H:%M:%S.%fZ',
            '%Y-%m-%dT%H:%M:%SZ',
            '%Y-%m-%d %H:%M:%S.%f'
        ]
        
        for fmt in formats:
            try:
                return datetime.strptime(timestamp_str.replace('Z', ''), fmt.replace('Z', ''))
            except ValueError:
                continue
        
        return datetime.now()

class LogPatternDetectorPlugin(ProblemDetectorPlugin):
    """Erkennt Probleme basierend auf Log-Mustern"""
    
    def __init__(self):
        self.patterns = []
        self.log_collector = None
        
    @property
    def name(self) -> str:
        return "log_pattern_detector"
    
    @property
    def version(self) -> str:
        return "1.0.0"
    
    async def initialize(self, config: Dict[str, Any]) -> bool:
        self._load_default_patterns()
        
        # Custom patterns aus config
        custom_patterns = config.get('custom_patterns', [])
        for pattern_config in custom_patterns:
            self.patterns.append({
                'name': pattern_config['name'],
                'pattern': re.compile(pattern_config['regex'], re.IGNORECASE),
                'severity': ProblemSeverity[pattern_config['severity'].upper()],
                'description': pattern_config['description']
            })
        
        logger.info(f"Loaded {len(self.patterns)} log patterns")
        return True
    
    async def cleanup(self) -> None:
        pass
    
    def _load_default_patterns(self):
        """Lädt Standard-Problemmuster"""
        default_patterns = [
            {
                'name': 'database_connection_error',
                'pattern': re.compile(r'(connection.*refused|could not connect|timeout.*database)', re.IGNORECASE),
                'severity': ProblemSeverity.CRITICAL,
                'description': 'Database connection issues detected'
            },
            {
                'name': 'out_of_memory',
                'pattern': re.compile(r'(out of memory|outofmemoryerror|memory allocation failed)', re.IGNORECASE),
                'severity': ProblemSeverity.CRITICAL,
                'description': 'Memory exhaustion detected'
            },
            {
                'name': 'authentication_failure',
                'pattern': re.compile(r'(auth.*failed|unauthorized|access denied|login.*failed)', re.IGNORECASE),
                'severity': ProblemSeverity.MEDIUM,
                'description': 'Authentication failures detected'
            },
            {
                'name': 'api_timeout',
                'pattern': re.compile(r'(timeout|request.*timed out|connection timeout)', re.IGNORECASE),
                'severity': ProblemSeverity.MEDIUM,
                'description': 'API timeout issues detected'
            }
        ]
        self.patterns.extend(default_patterns)
    
    async def detect_problems(self, metrics: Dict[str, Any], 
                            history: List[Dict[str, Any]]) -> List[Problem]:
        """Erkennt Probleme in Log-Daten"""
        problems = []
        
        # Get log collector from framework (simplified for prototype)
        if not self.log_collector:
            return problems
        
        recent_logs = list(self.log_collector.log_buffer)
        if not recent_logs:
            return problems
        
        # Pattern-basierte Erkennung
        pattern_matches = defaultdict(list)
        
        # Check recent logs (last 10 minutes)
        recent_threshold = datetime.now() - timedelta(minutes=10)
        
        for entry in recent_logs:
            if entry.timestamp < recent_threshold:
                continue
                
            for pattern in self.patterns:
                if (pattern['pattern'].search(entry.message) or 
                    pattern['pattern'].search(entry.raw_line)):
                    pattern_matches[pattern['name']].append(entry)
        
        # Create problems for matched patterns
        for pattern_name, matches in pattern_matches.items():
            if matches:
                pattern = next(p for p in self.patterns if p['name'] == pattern_name)
                
                problem = Problem(
                    type=f"log_pattern_{pattern_name}",
                    severity=pattern['severity'],
                    description=f"{pattern['description']} ({len(matches)} occurrences)",
                    timestamp=datetime.now(),
                    metadata={
                        'pattern_name': pattern_name,
                        'match_count': len(matches),
                        'sample_messages': [m.message for m in matches[:3]]
                    }
                )
                problems.append(problem)
        
        # Frequency-based detection
        recent_errors = [
            entry for entry in recent_logs 
            if entry.timestamp > recent_threshold and entry.level in ['ERROR', 'FATAL']
        ]
        
        if len(recent_errors) > 20:  # More than 20 errors in 10 minutes
            problem = Problem(
                type="log_error_frequency_high",
                severity=ProblemSeverity.HIGH if len(recent_errors) > 50 else ProblemSeverity.MEDIUM,
                description=f"High error frequency: {len(recent_errors)} errors in 10 minutes",
                timestamp=datetime.now(),
                metadata={'error_count': len(recent_errors)}
            )
            problems.append(problem)
        
        return problems
    
    def set_log_collector(self, collector):
        """Set reference to log collector (for prototype)"""
        self.log_collector = collector

# ============================================================================
# SYSTEM MONITORING PLUGINS
# ============================================================================

class SystemMetricsCollectorPlugin(MetricsCollectorPlugin):
    """Sammelt System-Metriken"""
    
    @property
    def name(self) -> str:
        return "system_metrics_collector"
    
    @property
    def version(self) -> str:
        return "1.0.0"
    
    async def initialize(self, config: Dict[str, Any]) -> bool:
        logger.info("Initialized system metrics collector")
        return True
    
    async def cleanup(self) -> None:
        pass
    
    async def collect_metrics(self) -> Dict[str, Any]:
        """Sammelt System-Metriken"""
        try:
            return {
                'cpu_usage': psutil.cpu_percent(interval=1),
                'memory_usage': psutil.virtual_memory().percent,
                'disk_usage': psutil.disk_usage('/').percent,
                'load_average': os.getloadavg()[0] if hasattr(os, 'getloadavg') else 0,
                'network_connections': len(psutil.net_connections()),
                'processes': len(psutil.pids()),
                'timestamp': time.time()
            }
        except Exception as e:
            logger.error(f"Error collecting system metrics: {e}")
            return {'system_metrics_error': str(e)}

class ThresholdDetectorPlugin(ProblemDetectorPlugin):
    """Schwellenwert-basierte Problem-Erkennung"""
    
    def __init__(self):
        self.thresholds = {}
        
    @property
    def name(self) -> str:
        return "threshold_detector"
    
    @property
    def version(self) -> str:
        return "1.0.0"
    
    async def initialize(self, config: Dict[str, Any]) -> bool:
        self.thresholds = config.get('thresholds', {
            'cpu_usage': {'warning': 80, 'critical': 95},
            'memory_usage': {'warning': 85, 'critical': 95},
            'disk_usage': {'warning': 85, 'critical': 95}
        })
        logger.info(f"Initialized threshold detector with {len(self.thresholds)} thresholds")
        return True
    
    async def cleanup(self) -> None:
        pass
    
    async def detect_problems(self, metrics: Dict[str, Any], 
                            history: List[Dict[str, Any]]) -> List[Problem]:
        """Erkennt Probleme basierend auf Schwellenwerten"""
        problems = []
        
        for metric_name, value in metrics.items():
            if metric_name in self.thresholds and isinstance(value, (int, float)):
                thresholds = self.thresholds[metric_name]
                
                if value >= thresholds['critical']:
                    problem = Problem(
                        type=f"{metric_name}_critical",
                        severity=ProblemSeverity.CRITICAL,
                        description=f"{metric_name} is critically high: {value}%",
                        timestamp=datetime.now(),
                        metadata={'metric': metric_name, 'value': value, 'threshold': thresholds['critical']}
                    )
                    problems.append(problem)
                    
                elif value >= thresholds['warning']:
                    problem = Problem(
                        type=f"{metric_name}_warning",
                        severity=ProblemSeverity.MEDIUM,
                        description=f"{metric_name} is above warning threshold: {value}%",
                        timestamp=datetime.now(),
                        metadata={'metric': metric_name, 'value': value, 'threshold': thresholds['warning']}
                    )
                    problems.append(problem)
        
        return problems

# ============================================================================
# REMEDIATION PLUGINS
# ============================================================================

class SystemRemediationPlugin(RemediationPlugin):
    """System-Level Problemlösungen"""
    
    def __init__(self):
        self.allowed_actions = []
        
    @property
    def name(self) -> str:
        return "system_remediation"
    
    @property
    def version(self) -> str:
        return "1.0.0"
    
    async def initialize(self, config: Dict[str, Any]) -> bool:
        self.allowed_actions = config.get('allowed_actions', [
            'clear_cache', 'log_rotation', 'process_restart'
        ])
        logger.info(f"Initialized system remediation with actions: {self.allowed_actions}")
        return True
    
    async def cleanup(self) -> None:
        pass
    
    async def can_handle_problem(self, problem: Problem) -> bool:
        """Prüft ob Problem behandelt werden kann"""
        return any(keyword in problem.type for keyword in ['cpu', 'memory', 'disk', 'system'])
    
    async def execute_remediation(self, problem: Problem, 
                                context: Dict[str, Any]) -> Dict[str, Any]:
        """Führt Problemlösung aus"""
        actions_taken = []
        
        try:
            if 'memory' in problem.type:
                actions_taken.extend(await self._handle_memory_problem(problem))
            elif 'cpu' in problem.type:
                actions_taken.extend(await self._handle_cpu_problem(problem))
            elif 'disk' in problem.type:
                actions_taken.extend(await self._handle_disk_problem(problem))
            
            return {
                'success': True,
                'actions_taken': actions_taken,
                'message': f"Problem handled with actions: {actions_taken}"
            }
            
        except Exception as e:
            logger.error(f"Remediation failed: {e}")
            return {
                'success': False,
                'actions_taken': actions_taken,
                'error': str(e)
            }
    
    async def _handle_memory_problem(self, problem: Problem) -> List[str]:
        """Behandelt Speicherprobleme"""
        actions = []
        
        if 'clear_cache' in self.allowed_actions:
            # Simulate cache clearing
            logger.info("Simulating memory cache clearing")
            actions.append('cleared_system_cache')
        
        return actions
    
    async def _handle_cpu_problem(self, problem: Problem) -> List[str]:
        """Behandelt CPU-Probleme"""
        actions = []
        
        if 'process_restart' in self.allowed_actions:
            # Simulate process management
            logger.info("Simulating CPU optimization")
            actions.append('optimized_cpu_usage')
        
        return actions
    
    async def _handle_disk_problem(self, problem: Problem) -> List[str]:
        """Behandelt Disk-Probleme"""
        actions = []
        
        if 'log_rotation' in self.allowed_actions:
            # Simulate log rotation
            logger.info("Simulating log rotation")
            actions.append('rotated_logs')
        
        return actions

# ============================================================================
# LEARNING ENGINE (Simplified for Prototype)
# ============================================================================

class SimpleLearningEngine:
    """Vereinfachte Lern-Engine für Prototyp"""
    
    def __init__(self, data_dir: str):
        self.data_dir = Path(data_dir)
        self.data_dir.mkdir(exist_ok=True)
        self.problem_history = []
        self.solution_success_rates = defaultdict(list)
        
    async def learn_from_intervention(self, problem: Problem, 
                                    solution_result: Dict[str, Any]):
        """Lernt aus Problemlösung"""
        self.problem_history.append({
            'problem': problem.to_dict(),
            'solution': solution_result,
            'timestamp': datetime.now().isoformat()
        })
        
        # Track success rates
        if solution_result.get('success'):
            self.solution_success_rates[problem.type].append(1)
        else:
            self.solution_success_rates[problem.type].append(0)
        
        logger.info(f"Learned from {problem.type}: success={solution_result.get('success')}")
    
    def get_success_rate(self, problem_type: str) -> float:
        """Gibt Erfolgsrate für Problemtyp zurück"""
        rates = self.solution_success_rates.get(problem_type, [])
        return sum(rates) / len(rates) if rates else 0.0
    
    def get_learning_summary(self) -> Dict[str, Any]:
        """Gibt Lern-Zusammenfassung zurück"""
        return {
            'total_interventions': len(self.problem_history),
            'problem_types_learned': len(self.solution_success_rates),
            'success_rates': {
                problem_type: self.get_success_rate(problem_type)
                for problem_type in self.solution_success_rates.keys()
            }
        }

# ============================================================================
# MAIN FRAMEWORK
# ============================================================================

class IntelligentMonitoringFramework:
    """Haupt-Framework Klasse"""
    
    def __init__(self, config: FrameworkConfig):
        self.config = config
        self.plugins = {
            'collectors': [],
            'detectors': [],
            'remediators': []
        }
        self.running = False
        self.metrics_history = deque(maxlen=1000)
        self.learning_engine = SimpleLearningEngine(config.data_dir)
        
        # Setup data directory
        Path(config.data_dir).mkdir(exist_ok=True)
        
    def register_plugin(self, plugin: PluginInterface, plugin_type: str):
        """Registriert Plugin"""
        if plugin_type in self.plugins:
            self.plugins[plugin_type].append(plugin)
            logger.info(f"Registered plugin: {plugin.name} ({plugin_type})")
    
    async def initialize(self):
        """Initialisiert Framework"""
        logger.info("Initializing Intelligent Monitoring Framework...")
        
        # Initialize all plugins
        for plugin_type, plugins in self.plugins.items():
            for plugin in plugins:
                try:
                    await plugin.initialize({})
                    logger.info(f"Initialized plugin: {plugin.name}")
                except Exception as e:
                    logger.error(f"Failed to initialize plugin {plugin.name}: {e}")
        
        # Setup plugin references for prototype
        log_collector = None
        log_detector = None
        
        for plugin in self.plugins['collectors']:
            if isinstance(plugin, LogFileCollectorPlugin):
                log_collector = plugin
                break
        
        for plugin in self.plugins['detectors']:
            if isinstance(plugin, LogPatternDetectorPlugin):
                log_detector = plugin
                break
        
        if log_collector and log_detector:
            log_detector.set_log_collector(log_collector)
        
        logger.info("Framework initialization complete")
    
    async def start(self):
        """Startet Monitoring"""
        if self.running:
            return
        
        self.running = True
        logger.info("Starting monitoring framework...")
        
        try:
            await self._monitoring_loop()
        except KeyboardInterrupt:
            logger.info("Monitoring interrupted by user")
        finally:
            await self.stop()
    
    async def stop(self):
        """Stoppt Framework"""
        if not self.running:
            return
        
        self.running = False
        logger.info("Stopping framework...")
        
        # Cleanup all plugins
        for plugin_type, plugins in self.plugins.items():
            for plugin in plugins:
                try:
                    await plugin.cleanup()
                except Exception as e:
                    logger.error(f"Error cleaning up plugin {plugin.name}: {e}")
        
        logger.info("Framework stopped")
    
    async def _monitoring_loop(self):
        """Haupt-Monitoring-Schleife"""
        while self.running:
            try:
                start_time = time.time()
                
                # Collect metrics
                all_metrics = await self._collect_metrics()
                
                # Store metrics
                self.metrics_history.append(all_metrics)
                
                # Detect problems
                problems = await self._detect_problems(all_metrics)
                
                # Handle problems
                for problem in problems:
                    await self._handle_problem(problem, all_metrics)
                
                # Log status
                cycle_time = time.time() - start_time
                logger.info(f"Monitoring cycle completed in {cycle_time:.2f}s - "
                          f"Metrics: {len(all_metrics)}, Problems: {len(problems)}")
                
                # Wait for next cycle
                await asyncio.sleep(max(0, self.config.monitoring_interval - cycle_time))
                
            except Exception as e:
                logger.error(f"Error in monitoring loop: {e}")
                await asyncio.sleep(5)
    
    async def _collect_metrics(self) -> Dict[str, Any]:
        """Sammelt Metriken von allen Kollektoren"""
        all_metrics = {'timestamp': time.time()}
        
        for collector in self.plugins['collectors']:
            try:
                metrics = await collector.collect_metrics()
                all_metrics.update(metrics)
            except Exception as e:
                logger.error(f"Error collecting metrics from {collector.name}: {e}")
        
        return all_metrics
    
    async def _detect_problems(self, metrics: Dict[str, Any]) -> List[Problem]:
        """Erkennt Probleme mit allen Detektoren"""
        all_problems = []
        history = list(self.metrics_history)
        
        for detector in self.plugins['detectors']:
            try:
                problems = await detector.detect_problems(metrics, history)
                all_problems.extend(problems)
            except Exception as e:
                logger.error(f"Error detecting problems with {detector.name}: {e}")
        
        return all_problems
    
    async def _handle_problem(self, problem: Problem, metrics: Dict[str, Any]):
        """Behandelt erkanntes Problem"""
        logger.warning(f"Problem detected: {problem.description}")
        
        if not self.config.auto_remediation:
            return
        
        # Find suitable remediator
        for remediator in self.plugins['remediators']:
            try:
                if await remediator.can_handle_problem(problem):
                    logger.info(f"Attempting remediation with {remediator.name}")
                    
                    result = await remediator.execute_remediation(problem, {
                        'metrics': metrics,
                        'timestamp': time.time()
                    })
                    
                    # Learn from result
                    await self.learning_engine.learn_from_intervention(problem, result)
                    
                    if result.get('success'):
                        logger.info(f"Problem remediated successfully: {result.get('message')}")
                    else:
                        logger.warning(f"Remediation failed: {result.get('error')}")
                    
                    break
            except Exception as e:
                logger.error(f"Error in remediation with {remediator.name}: {e}")
    
    def get_status(self) -> Dict[str, Any]:
        """Gibt Framework-Status zurück"""
        return {
            'running': self.running,
            'config': asdict(self.config),
            'plugins': {
                plugin_type: [plugin.name for plugin in plugins]
                for plugin_type, plugins in self.plugins.items()
            },
            'metrics_history_size': len(self.metrics_history),
            'learning_summary': self.learning_engine.get_learning_summary()
        }

# ============================================================================
# FACTORY FUNCTIONS
# ============================================================================

async def create_mcp_framework(log_files: List[Dict[str, str]] = None) -> IntelligentMonitoringFramework:
    """Erstellt Framework für MCP Server Monitoring"""
    
    config = FrameworkConfig(
        server_type="mcp",
        monitoring_interval=30,
        learning_enabled=True,
        auto_remediation=True
    )
    
    framework = IntelligentMonitoringFramework(config)
    
    # System Metrics
    system_collector = SystemMetricsCollectorPlugin()
    framework.register_plugin(system_collector, 'collectors')
    
    # Log Monitoring
    if log_files:
        log_collector = LogFileCollectorPlugin()
        await log_collector.initialize({'log_files': log_files})
        framework.register_plugin(log_collector, 'collectors')
        
        # Log Pattern Detection
        log_detector = LogPatternDetectorPlugin()
        framework.register_plugin(log_detector, 'detectors')
    
    # Threshold Detection
    threshold_detector = ThresholdDetectorPlugin()
    framework.register_plugin(threshold_detector, 'detectors')
    
    # System Remediation
    system_remediation = SystemRemediationPlugin()
    framework.register_plugin(system_remediation, 'remediators')
    
    await framework.initialize()
    return framework

# ============================================================================
# CONFIGURATION LOADER
# ============================================================================

def load_config_from_file(config_path: str) -> Dict[str, Any]:
    """Lädt Konfiguration aus YAML-Datei"""
    try:
        with open(config_path, 'r') as f:
            return yaml.safe_load(f)
    except Exception as e:
        logger.error(f"Error loading config from {config_path}: {e}")
        return {}

async def create_framework_from_config(config_path: str) -> IntelligentMonitoringFramework:
    """Erstellt Framework aus Konfigurationsdatei"""
    config_data = load_config_from_file(config_path)
    
    # Framework Config
    framework_config = FrameworkConfig(
        server_type=config_data.get('server_type', 'generic'),
        monitoring_interval=config_data.get('monitoring_interval', 30),
        learning_enabled=config_data.get('learning_enabled', True),
        auto_remediation=config_data.get('auto_remediation', True)
    )
    
    framework = IntelligentMonitoringFramework(framework_config)
    
    # Load plugins based on config
    plugins_config = config_data.get('plugins', {})
    
    # Metrics collectors
    for collector_config in plugins_config.get('metrics_collectors', []):
        if collector_config['name'] == 'log_file_collector':
            plugin = LogFileCollectorPlugin()
            await plugin.initialize(collector_config.get('config', {}))
            framework.register_plugin(plugin, 'collectors')
        elif collector_config['name'] == 'system_metrics_collector':
            plugin = SystemMetricsCollectorPlugin()
            await plugin.initialize(collector_config.get('config', {}))
            framework.register_plugin(plugin, 'collectors')
    
    # Problem detectors
    for detector_config in plugins_config.get('problem_detectors', []):
        if detector_config['name'] == 'log_pattern_detector':
            plugin = LogPatternDetectorPlugin()
            await plugin.initialize(detector_config.get('config', {}))
            framework.register_plugin(plugin, 'detectors')
        elif detector_config['name'] == 'threshold_detector':
            plugin = ThresholdDetectorPlugin()
            await plugin.initialize(detector_config.get('config', {}))
            framework.register_plugin(plugin, 'detectors')
    
    # Remediators
    for remediation_config in plugins_config.get('remediators', []):
        if remediation_config['name'] == 'system_remediation':
            plugin = SystemRemediationPlugin()
            await plugin.initialize(remediation_config.get('config', {}))
            framework.register_plugin(plugin, 'remediators')
    
    await framework.initialize()
    return framework

# ============================================================================
# CLI INTERFACE
# ============================================================================

class FrameworkCLI:
    """Command Line Interface für das Framework"""
    
    def __init__(self):
        self.framework = None
    
    async def run_interactive(self):
        """Interaktiver Modus"""
        print("🤖 Intelligent Monitoring Framework - Interactive Mode")
        print("=" * 60)
        
        while True:
            try:
                print("\nCommands:")
                print("1. start - Start monitoring")
                print("2. status - Show framework status")
                print("3. config - Create sample configuration")
                print("4. demo - Run demo with sample data")
                print("5. quit - Exit")
                
                choice = input("\nEnter command: ").strip().lower()
                
                if choice in ['1', 'start']:
                    await self._start_monitoring()
                elif choice in ['2', 'status']:
                    await self._show_status()
                elif choice in ['3', 'config']:
                    self._create_sample_config()
                elif choice in ['4', 'demo']:
                    await self._run_demo()
                elif choice in ['5', 'quit', 'exit']:
                    break
                else:
                    print("Invalid command")
                    
            except KeyboardInterrupt:
                print("\nExiting...")
                break
        
        if self.framework:
            await self.framework.stop()
    
    async def _start_monitoring(self):
        """Startet Monitoring"""
        print("\n🚀 Starting monitoring framework...")
        
        # Check for config file
        config_file = "config.yaml"
        if Path(config_file).exists():
            print(f"Loading configuration from {config_file}")
            self.framework = await create_framework_from_config(config_file)
        else:
            print("No config file found, using default MCP configuration")
            log_files = [
                {'path': '/var/log/syslog', 'type': 'syslog'},
                {'path': './test.log', 'type': 'application'}
            ]
            self.framework = await create_mcp_framework(log_files)
        
        print("Framework started! Press Ctrl+C to stop monitoring.")
        await self.framework.start()
    
    async def _show_status(self):
        """Zeigt Framework-Status"""
        if not self.framework:
            print("Framework not started yet")
            return
        
        status = self.framework.get_status()
        print("\n📊 Framework Status:")
        print(f"Running: {status['running']}")
        print(f"Server Type: {status['config']['server_type']}")
        print(f"Monitoring Interval: {status['config']['monitoring_interval']}s")
        print(f"Auto Remediation: {status['config']['auto_remediation']}")
        print(f"Learning Enabled: {status['config']['learning_enabled']}")
        
        print("\n🔌 Loaded Plugins:")
        for plugin_type, plugins in status['plugins'].items():
            print(f"  {plugin_type.capitalize()}: {', '.join(plugins)}")
        
        print(f"\n📈 Metrics History: {status['metrics_history_size']} entries")
        
        learning = status['learning_summary']
        print(f"\n🧠 Learning Summary:")
        print(f"  Total Interventions: {learning['total_interventions']}")
        print(f"  Problem Types Learned: {learning['problem_types_learned']}")
        
        if learning['success_rates']:
            print("  Success Rates:")
            for problem_type, rate in learning['success_rates'].items():
                print(f"    {problem_type}: {rate:.1%}")
    
    def _create_sample_config(self):
        """Erstellt Beispiel-Konfiguration"""
        sample_config = {
            'server_type': 'mcp',
            'monitoring_interval': 30,
            'learning_enabled': True,
            'auto_remediation': True,
            'plugins': {
                'metrics_collectors': [
                    {
                        'name': 'system_metrics_collector',
                        'config': {}
                    },
                    {
                        'name': 'log_file_collector',
                        'config': {
                            'log_files': [
                                {'path': '/var/log/syslog', 'type': 'syslog'},
                                {'path': './application.log', 'type': 'application'},
                                {'path': './error.log', 'type': 'application'}
                            ]
                        }
                    }
                ],
                'problem_detectors': [
                    {
                        'name': 'threshold_detector',
                        'config': {
                            'thresholds': {
                                'cpu_usage': {'warning': 80, 'critical': 95},
                                'memory_usage': {'warning': 85, 'critical': 95},
                                'disk_usage': {'warning': 85, 'critical': 95}
                            }
                        }
                    },
                    {
                        'name': 'log_pattern_detector',
                        'config': {
                            'custom_patterns': [
                                {
                                    'name': 'payment_failure',
                                    'regex': '(payment.*failed|transaction.*declined)',
                                    'severity': 'critical',
                                    'description': 'Payment processing failures'
                                }
                            ]
                        }
                    }
                ],
                'remediators': [
                    {
                        'name': 'system_remediation',
                        'config': {
                            'allowed_actions': ['clear_cache', 'log_rotation', 'process_restart']
                        }
                    }
                ]
            }
        }
        
        config_file = "config.yaml"
        with open(config_file, 'w') as f:
            yaml.dump(sample_config, f, default_flow_style=False, indent=2)
        
        print(f"✅ Sample configuration created: {config_file}")
        print("You can edit this file and restart the framework to use it.")
    
    async def _run_demo(self):
        """Führt Demo mit Beispiel-Daten aus"""
        print("\n🎬 Running demonstration...")
        
        # Create demo log file
        demo_log_file = "demo.log"
        demo_logs = [
            f"{datetime.now().strftime('%Y-%m-%d %H:%M:%S')} INFO Application started",
            f"{datetime.now().strftime('%Y-%m-%d %H:%M:%S')} WARNING High memory usage detected",
            f"{datetime.now().strftime('%Y-%m-%d %H:%M:%S')} ERROR Database connection failed",
            f"{datetime.now().strftime('%Y-%m-%d %H:%M:%S')} ERROR Out of memory error occurred",
            f"{datetime.now().strftime('%Y-%m-%d %H:%M:%S')} INFO Request processed successfully"
        ]
        
        with open(demo_log_file, 'w') as f:
            f.write('\n'.join(demo_logs))
        
        print(f"Created demo log file: {demo_log_file}")
        
        # Create framework with demo configuration
        log_files = [{'path': demo_log_file, 'type': 'application'}]
        self.framework = await create_mcp_framework(log_files)
        
        print("Framework initialized. Running one monitoring cycle...")
        
        # Run one cycle
        metrics = await self.framework._collect_metrics()
        problems = await self.framework._detect_problems(metrics)
        
        print(f"\n📊 Collected Metrics: {len(metrics)} items")
        for key, value in metrics.items():
            if isinstance(value, (int, float)) and key != 'timestamp':
                print(f"  {key}: {value}")
        
        print(f"\n🚨 Detected Problems: {len(problems)}")
        for problem in problems:
            print(f"  [{problem.severity.name}] {problem.description}")
        
        # Handle problems
        for problem in problems:
            await self.framework._handle_problem(problem, metrics)
        
        # Show learning results
        learning = self.framework.learning_engine.get_learning_summary()
        print(f"\n🧠 Learning Results:")
        print(f"  Interventions: {learning['total_interventions']}")
        
        # Cleanup
        Path(demo_log_file).unlink(missing_ok=True)
        await self.framework.stop()
        self.framework = None
        
        print("✅ Demo completed!")

# ============================================================================
# MAIN ENTRY POINT
# ============================================================================

async def main():
    """Haupt-Einstiegspunkt"""
    if len(sys.argv) > 1:
        command = sys.argv[1].lower()
        
        if command == 'start':
            # Direct start with config file
            config_file = sys.argv[2] if len(sys.argv) > 2 else "config.yaml"
            
            if Path(config_file).exists():
                framework = await create_framework_from_config(config_file)
            else:
                print(f"Config file {config_file} not found, using defaults")
                framework = await create_mcp_framework()
            
            print("🚀 Starting Intelligent Monitoring Framework...")
            await framework.start()
            
        elif command == 'demo':
            # Quick demo
            cli = FrameworkCLI()
            await cli._run_demo()
            
        elif command == 'config':
            # Generate sample config
            cli = FrameworkCLI()
            cli._create_sample_config()
            
        else:
            print("Usage: python framework.py [start|demo|config|interactive]")
    else:
        # Interactive mode
        cli = FrameworkCLI()
        await cli.run_interactive()

if __name__ == "__main__":
    print("🤖 Intelligent Monitoring Framework v1.0.0")
    print("Author: AI Assistant")
    print("=" * 60)
    
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        print("\nGoodbye! 👋")
    except Exception as e:
        logger.error(f"Unexpected error: {e}")
        sys.exit(1)